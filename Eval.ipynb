{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "887f3e5e-5d17-48bb-92d0-55512bbbb84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    GenerationConfig,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaTokenizer,\n",
    "    pipeline,\n",
    ")\n",
    "import os\n",
    "import logging\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from evaluate import evaluator\n",
    "from datasets import Dataset\n",
    "from evaluate import load\n",
    "\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = \"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\"\n",
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1daba56d-1098-4ebf-8f96-c0176c0dd168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# model_name = \"atom92/medical_lama_2_all\"\n",
    "# model_name = \"atom92/medical_lama_ultra\"\n",
    "model_name = \"atom92/medical-token-llama-2-healthwa-3\"\n",
    "\n",
    "# dataset_name = \"atom92/medical_healthwa_all_2.0\"\n",
    "dataset_name = \"atom92/medical_healthwa_2.0\"\n",
    "\n",
    "eval_set_size = 0.05\n",
    "device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23922160-207b-4e1d-a39f-06e8a5a14668",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = load_dataset(dataset_name, split=\"train\")\n",
    "splitted_dataset = my_dataset.train_test_split(test_size=eval_set_size, shuffle=True, seed=42)\n",
    "eval_dataset = splitted_dataset[\"test\"].shuffle(seed=42).select(range(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f82a31f-10a0-4898-8d91-94070e485fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab9950be56e494c866dae20200ac1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3773a3ba4ada4678b876895222e4ff11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9424071ec784210ae4c4ff0b4a08f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "logging.info(\"Tokenizer loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffe54af9-9687-41e9-bce4-4a2abf3896d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead24afb273f4d1fb6d6227626840647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/661 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b1ec7d3060469dad06293b4f69fbaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152e2e59b87845c99ea00a8ed9e82e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778b2d16a8794406818f7ff9b5c533dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca11156789d4efab1eb206827ed5252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af841f0c05f44f8a97eda810cb3aadc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2e4fee962b4f3ab316a248a165b81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/183 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device_map,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True,\n",
    "    max_memory={0: \"14GiB\", 1: \"14GiB\"},\n",
    "    offload_folder=\"/tmp/offload\"\n",
    ")\n",
    "model.tie_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac1d42bd-7fa8-401b-813d-9f15382d8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=254,\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    top_p=0.5,\n",
    "    top_k=50,\n",
    "    repetition_penalty=1.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d05b13ad-ae56-4972-9dad-70603b85dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_evaluator = evaluator(\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e7905c4-4bf2-4eb7-ab32-f30a42e30b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_question_and_context(text):\n",
    "    # Assuming the structure is <START_Q> Question <END_Q><START_A> Answer <END_A>\n",
    "    split_text = text.split(\"<END_Q>\")\n",
    "    question = split_text[0].replace(\"<START_Q>\", \"\").strip()\n",
    "    answer = split_text[1].replace(\"<START_A>\", \"\").split(\"<END_A>\")[0].strip()\n",
    "    return question, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce7575b2-1bad-4881-9d0d-95ebfcb2754b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257\n",
      "207\n",
      "158\n",
      "216\n",
      "125\n",
      "178\n",
      "242\n",
      "185\n",
      "220\n",
      "328\n",
      "218\n",
      "249\n",
      "234\n",
      "165\n",
      "168\n",
      "307\n",
      "203\n",
      "231\n",
      "180\n",
      "286\n",
      "195\n",
      "173\n",
      "261\n",
      "250\n",
      "242\n",
      "216\n",
      "190\n",
      "155\n",
      "207\n",
      "231\n",
      "215\n",
      "323\n",
      "153\n",
      "200\n",
      "269\n",
      "196\n",
      "309\n",
      "204\n",
      "191\n",
      "214\n",
      "173\n",
      "147\n",
      "234\n",
      "240\n",
      "228\n",
      "178\n",
      "228\n",
      "185\n",
      "238\n",
      "212\n",
      "232\n",
      "381\n",
      "225\n",
      "169\n",
      "254\n",
      "154\n",
      "205\n",
      "260\n",
      "172\n",
      "183\n",
      "168\n",
      "155\n",
      "209\n",
      "250\n",
      "302\n",
      "258\n",
      "179\n",
      "190\n",
      "198\n",
      "185\n",
      "157\n",
      "199\n",
      "198\n",
      "159\n",
      "155\n",
      "150\n",
      "230\n",
      "165\n",
      "204\n",
      "194\n",
      "242\n",
      "166\n",
      "132\n",
      "215\n",
      "264\n",
      "258\n",
      "241\n",
      "148\n",
      "180\n",
      "168\n",
      "154\n",
      "352\n",
      "244\n",
      "176\n",
      "158\n",
      "175\n",
      "210\n",
      "142\n",
      "286\n",
      "206\n",
      "223\n",
      "200\n",
      "243\n",
      "194\n",
      "164\n",
      "225\n",
      "263\n",
      "204\n",
      "206\n",
      "223\n",
      "181\n",
      "258\n",
      "197\n",
      "239\n",
      "136\n",
      "247\n",
      "206\n",
      "189\n",
      "165\n",
      "200\n",
      "241\n",
      "234\n",
      "188\n",
      "208\n",
      "167\n",
      "119\n",
      "171\n",
      "154\n",
      "227\n",
      "175\n",
      "250\n",
      "180\n",
      "219\n",
      "231\n",
      "200\n",
      "204\n",
      "181\n",
      "247\n",
      "208\n",
      "211\n",
      "206\n",
      "236\n",
      "182\n",
      "184\n",
      "140\n",
      "234\n",
      "228\n",
      "414\n",
      "162\n",
      "212\n",
      "300\n",
      "194\n",
      "151\n",
      "171\n",
      "152\n",
      "220\n",
      "237\n",
      "242\n",
      "240\n",
      "232\n",
      "242\n",
      "117\n",
      "273\n",
      "178\n",
      "189\n",
      "134\n",
      "221\n",
      "194\n",
      "243\n",
      "114\n",
      "242\n",
      "213\n",
      "229\n",
      "230\n",
      "226\n",
      "202\n",
      "190\n",
      "166\n",
      "204\n",
      "167\n",
      "233\n",
      "184\n",
      "247\n",
      "209\n",
      "208\n",
      "112\n",
      "123\n",
      "210\n",
      "200\n",
      "180\n",
      "199\n",
      "189\n",
      "182\n",
      "217\n",
      "204\n",
      "206\n",
      "244\n",
      "201\n",
      "181\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "for a in eval_dataset:\n",
    "    print(len(a[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6a8a7ab-f107-44ff-be68-ce9d49ce185c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/llm-fine-tune/myenv/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "references = []\n",
    "i = 0\n",
    "for example in eval_dataset:\n",
    "    i += 1\n",
    "    text = example[\"text\"]\n",
    "    if len(text) > 4000:\n",
    "        continue\n",
    "    question, answer = extract_question_and_context(text)\n",
    "    output = pipe(question)[0]['generated_text']\n",
    "    predictions.append(output)\n",
    "    references.append(answer)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad2e40f6-3540-413b-8d4a-0777266e93e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.030353401133646523, 'precisions': [0.07853891606118006, 0.03542691421910096, 0.02156072174087101, 0.01414972246987432], 'brevity_penalty': 1.0, 'length_ratio': 7.844533155910401, 'translation_length': 35371, 'reference_length': 4509}\n"
     ]
    }
   ],
   "source": [
    "bleu = load(\"bleu\")\n",
    "results = bleu.compute(predictions=predictions, references=references)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d312b3d4-b33c-40cd-a5fc-15d873315223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.15680794725779068, 'rouge2': 0.07305553977871666, 'rougeL': 0.12619204323657254, 'rougeLsum': 0.13199990816171295}\n"
     ]
    }
   ],
   "source": [
    "rouge = load('rouge')\n",
    "results_rouge = rouge.compute(predictions=predictions, references=references)\n",
    "print(results_rouge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76ae1510-0997-41f3-b884-0ba852c5413d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': [0.8246970772743225, 0.8161670565605164, 0.8279719352722168, 0.8142661452293396, 0.8061047196388245, 0.8649982213973999, 0.7918987274169922, 0.8060519695281982, 0.8282644748687744, 0.8475676774978638, 0.8123444318771362, 0.8711321353912354, 0.8331756591796875, 0.8080877065658569, 0.8399752378463745, 0.868878960609436, 0.7760570049285889, 0.872739851474762, 0.8056360483169556, 0.7780874967575073, 0.7926252484321594, 0.8356372117996216, 0.8434336185455322, 0.8140913248062134, 0.8135113716125488, 0.8400270342826843, 0.8069626092910767, 0.8006922006607056, 0.7841464281082153, 0.8216689825057983, 0.8200308680534363, 0.829421877861023, 0.8185296058654785, 0.800727128982544, 0.8623119592666626, 0.8260265588760376, 0.8852423429489136, 0.7830050587654114, 0.8214080929756165, 0.8181259632110596, 0.8112436532974243, 0.7819122076034546, 0.8133894205093384, 0.817094087600708, 0.8416652679443359, 0.8863526582717896, 0.793402910232544, 0.8400000929832458, 0.8669695258140564, 0.7996306419372559, 0.8125612735748291, 0.8250302076339722, 0.873823881149292, 0.7908021807670593, 0.8054358959197998, 0.8088897466659546, 0.8830887675285339, 0.7967409491539001, 0.8373368978500366, 0.8119519948959351, 0.8245583176612854, 0.8053838014602661, 0.8083152770996094, 0.7840237617492676, 0.8201333284378052, 0.821342945098877, 0.8186368346214294, 0.8047434091567993, 0.8686702847480774, 0.821179986000061, 0.8445197939872742, 0.7880507111549377, 0.8045487403869629, 0.7784218788146973, 0.8091655969619751, 0.7869583368301392, 0.8336478471755981, 0.8509693145751953, 0.820766806602478, 0.833309531211853, 0.8219170570373535, 0.8765870928764343, 0.7725568413734436, 0.8044382929801941, 0.8421505689620972, 0.850214958190918, 0.824052095413208, 0.7886780500411987, 0.7740215063095093, 0.8053634166717529, 0.7978217601776123, 0.8232427835464478, 0.7762801051139832, 0.8073269724845886, 0.8119769096374512, 0.8198251724243164, 0.8065120577812195, 0.8168829679489136, 0.8067468404769897, 0.8225640058517456, 0.8250594735145569, 0.8648495674133301, 0.8303288221359253, 0.8303666114807129, 0.7520608305931091, 0.8061587810516357, 0.7942842245101929, 0.8378643989562988, 0.8161233067512512, 0.7666623592376709, 0.8178240060806274, 0.8264623880386353, 0.8178869485855103, 0.8419530391693115, 0.8093185424804688, 0.7987998723983765, 0.8119829893112183, 0.8365401029586792, 0.8080871105194092, 0.8176580667495728, 0.7977007627487183, 0.8291242718696594, 0.8163918256759644, 0.7898786067962646, 0.813163697719574, 0.7878983616828918, 0.8373206853866577, 0.832506000995636, 0.8129819631576538, 0.7992161512374878, 0.8396228551864624, 0.822907567024231, 0.8313183188438416, 0.8282459378242493, 0.8209635615348816, 0.8254456520080566, 0.835168719291687, 0.808504045009613, 0.7764791250228882, 0.8293019533157349, 0.8221642971038818, 0.7986749410629272, 0.8283403515815735, 0.8174371719360352, 0.7967569828033447, 0.829888641834259, 0.8138067722320557, 0.8490540981292725, 0.904808759689331, 0.8484470248222351, 0.821846604347229, 0.8150525093078613, 0.8028101921081543, 0.8210632801055908, 0.7944687008857727, 0.8321887254714966, 0.8175386190414429, 0.8135291337966919, 0.8152669072151184, 0.7820724844932556, 0.8281781673431396, 0.7814617156982422, 0.8352102041244507, 0.8260452151298523, 0.834347128868103, 0.7952443361282349, 0.9166926741600037, 0.8231076598167419, 0.8270338773727417, 0.8065958023071289, 0.8061298131942749, 0.8016035556793213, 0.832623302936554, 0.8432013392448425, 0.7986270189285278, 0.8049764633178711, 0.8143419623374939, 0.8257224559783936, 0.8168432712554932, 0.8361440300941467, 0.8288761377334595, 0.8162238597869873, 0.8133319616317749, 0.7938531637191772, 0.7951411008834839, 0.8079791069030762, 0.8087178468704224, 0.8267660140991211, 0.8236437439918518, 0.7718822956085205, 0.7954797744750977, 0.7940785884857178, 0.7798217535018921, 0.7945332527160645, 0.8312031030654907, 0.8247653841972351, 0.7822752594947815, 0.8091417551040649, 0.8551672697067261, 0.8177332878112793], 'recall': [0.8926012516021729, 0.8871144652366638, 0.9212062954902649, 0.9042980670928955, 0.9051697254180908, 0.9449734687805176, 0.8414342403411865, 0.9195572137832642, 0.9417065382003784, 0.8670385479927063, 0.8678789734840393, 0.871063768863678, 0.871674656867981, 0.9024864435195923, 0.9120761156082153, 0.8694466948509216, 0.8833978772163391, 0.8947145938873291, 0.9358314275741577, 0.8181325197219849, 0.8995646238327026, 0.9055068492889404, 0.8778408765792847, 0.8454746603965759, 0.9026106595993042, 0.8801026940345764, 0.9118655323982239, 0.884716808795929, 0.8689196109771729, 0.8635332584381104, 0.9143686294555664, 0.8657865524291992, 0.8869404792785645, 0.8591798543930054, 0.9199222922325134, 0.901874303817749, 0.9114777445793152, 0.8471084833145142, 0.868868350982666, 0.8847697973251343, 0.9323692321777344, 0.8765993118286133, 0.873009979724884, 0.9327517747879028, 0.9145272970199585, 0.9200809001922607, 0.9135597348213196, 0.9097605347633362, 0.8975918292999268, 0.8811408281326294, 0.8968214392662048, 0.8664188981056213, 0.9274600148200989, 0.8890971541404724, 0.900490939617157, 0.9070455431938171, 0.9144444465637207, 0.8698340058326721, 0.9202475547790527, 0.9374157786369324, 0.9021385908126831, 0.8827257752418518, 0.929726779460907, 0.8551771640777588, 0.8763940334320068, 0.8934997916221619, 0.9370332956314087, 0.8829789757728577, 0.8903798460960388, 0.9145671725273132, 0.9254493713378906, 0.8625108599662781, 0.8920344710350037, 0.8942535519599915, 0.885874330997467, 0.9098082184791565, 0.9057425856590271, 0.8980123400688171, 0.8912426233291626, 0.8920995593070984, 0.8842179775238037, 0.9177232980728149, 0.8643088340759277, 0.9372352361679077, 0.8991503119468689, 0.9071024060249329, 0.9473215341567993, 0.8585383892059326, 0.8577675819396973, 0.8714765310287476, 0.9068355560302734, 0.8822292685508728, 0.7959614992141724, 0.8941845893859863, 0.9275182485580444, 0.8802450895309448, 0.9414064884185791, 0.907407820224762, 0.8447734117507935, 0.8989089727401733, 0.8869473934173584, 0.9175680875778198, 0.9168517589569092, 0.8912041187286377, 0.9289013147354126, 0.9039269089698792, 0.8631969690322876, 0.8974438905715942, 0.8803988695144653, 0.7986240386962891, 0.905158281326294, 0.8592668771743774, 0.9018657207489014, 0.9209299087524414, 0.896121621131897, 0.8916449546813965, 0.8876705765724182, 0.92859947681427, 0.8867259621620178, 0.8889052867889404, 0.8738068342208862, 0.9176191687583923, 0.8911038041114807, 0.864057183265686, 0.9216270446777344, 0.9269223213195801, 0.8880617022514343, 0.8996965885162354, 0.9251144528388977, 0.8946657180786133, 0.9175789952278137, 0.9087408185005188, 0.9025735855102539, 0.9275939464569092, 0.9175606369972229, 0.8865952491760254, 0.9420813322067261, 0.9136239290237427, 0.8772695660591125, 0.9054010510444641, 0.9153233766555786, 0.8676549792289734, 0.9006155729293823, 0.845238447189331, 0.8590050339698792, 0.8921234011650085, 0.8427358269691467, 0.8820804953575134, 0.9395754337310791, 0.8944675326347351, 0.9029051661491394, 0.9017590880393982, 0.8989223837852478, 0.8726488351821899, 0.8836627006530762, 0.8860787749290466, 0.8936450481414795, 0.7941951751708984, 0.877428412437439, 0.8710837364196777, 0.8994861245155334, 0.8930934071540833, 0.9048065543174744, 0.9093431830406189, 0.888513445854187, 0.900329053401947, 0.945586621761322, 0.9143370985984802, 0.9015694856643677, 0.8814723491668701, 0.8930320739746094, 0.8755607604980469, 0.9071467518806458, 0.8848364353179932, 0.8595297336578369, 0.8860705494880676, 0.8929675221443176, 0.9216387867927551, 0.9204248785972595, 0.9103521704673767, 0.8694849610328674, 0.9260584712028503, 0.8760658502578735, 0.9005650281906128, 0.8639367818832397, 0.9126594066619873, 0.9118730425834656, 0.8932946920394897, 0.8663859963417053, 0.882195234298706, 0.8779003620147705, 0.9039271473884583, 0.8949167132377625, 0.8724278211593628, 0.8964719772338867, 0.9015527963638306, 0.836449146270752, 0.916236400604248, 0.9047351479530334, 0.9201737642288208], 'f1': [0.857306718826294, 0.8501631617546082, 0.8721044063568115, 0.8569238185882568, 0.8527698516845703, 0.9032189846038818, 0.8159153461456299, 0.8590715527534485, 0.8813501000404358, 0.8571925163269043, 0.8391939401626587, 0.871097981929779, 0.8519904613494873, 0.8526824116706848, 0.8745421171188354, 0.8691627383232117, 0.8262557983398438, 0.8835906386375427, 0.8658668994903564, 0.7976076602935791, 0.842715859413147, 0.8691701889038086, 0.8602933287620544, 0.8294862508773804, 0.8557480573654175, 0.8595979809761047, 0.856212854385376, 0.8406099677085876, 0.8243592977523804, 0.8420811295509338, 0.864634096622467, 0.8472142219543457, 0.851362943649292, 0.828924298286438, 0.8901860117912292, 0.8622857332229614, 0.8981685042381287, 0.8137962818145752, 0.8444719314575195, 0.8501438498497009, 0.8675993084907532, 0.8265528678894043, 0.8421457409858704, 0.871100664138794, 0.8765848278999329, 0.9029019474983215, 0.8492523431777954, 0.8734897375106812, 0.8820149302482605, 0.8384093046188354, 0.8526146411895752, 0.8452181220054626, 0.8998434543609619, 0.8370739221572876, 0.8503151535987854, 0.8551602959632874, 0.8984931111335754, 0.8316846489906311, 0.8768366575241089, 0.8701847791671753, 0.8616056442260742, 0.8422830104827881, 0.8647803664207458, 0.8180562257766724, 0.8473308086395264, 0.8559032082557678, 0.8738429546356201, 0.8420478701591492, 0.879391074180603, 0.8653613924980164, 0.8831343650817871, 0.823601245880127, 0.8460359573364258, 0.832327127456665, 0.8457842469215393, 0.8439359664916992, 0.8682011365890503, 0.8738581538200378, 0.8545541167259216, 0.8617030382156372, 0.8519300222396851, 0.8966836929321289, 0.8158613443374634, 0.8657741546630859, 0.8697175979614258, 0.8777379393577576, 0.8813976645469666, 0.8221268057823181, 0.8137454986572266, 0.8371165990829468, 0.8488429188728333, 0.8517159819602966, 0.7859976291656494, 0.8485388159751892, 0.8659102916717529, 0.8489614725112915, 0.8687540888786316, 0.8597691059112549, 0.8253223299980164, 0.8590435981750488, 0.8548848628997803, 0.8904291987419128, 0.8714479207992554, 0.8597103953361511, 0.8311790823936462, 0.8522481322288513, 0.8273079991340637, 0.8666313290596008, 0.8470434546470642, 0.7823169231414795, 0.8592777848243713, 0.8425453901290894, 0.8578259348869324, 0.8796723484992981, 0.8505110740661621, 0.8426727056503296, 0.8481414914131165, 0.880169153213501, 0.8455821871757507, 0.851794421672821, 0.8340212106704712, 0.8711300492286682, 0.8521133065223694, 0.8253044486045837, 0.8640046119689941, 0.8517748713493347, 0.8619451522827148, 0.8647981882095337, 0.8654310703277588, 0.8442516326904297, 0.8768717050552368, 0.8636969327926636, 0.8654817938804626, 0.8751093149185181, 0.8665785193443298, 0.8549284338951111, 0.8854092955589294, 0.8578556776046753, 0.8238028883934021, 0.8656823039054871, 0.8662463426589966, 0.831737220287323, 0.8629672527313232, 0.8311054110527039, 0.8267109394073486, 0.8598814010620117, 0.8280187249183655, 0.8652521967887878, 0.9218644499778748, 0.8708497285842896, 0.8604711294174194, 0.8562162518501282, 0.8481521010398865, 0.8460704684257507, 0.8366953730583191, 0.8582887649536133, 0.853899359703064, 0.8037459254264832, 0.8452062606811523, 0.8241817951202393, 0.8623605966567993, 0.8335567116737366, 0.8686165809631348, 0.865695059299469, 0.8605788350105286, 0.8445304036140442, 0.9309155344963074, 0.8663272261619568, 0.8626947402954102, 0.8423734903335571, 0.8473586440086365, 0.8369515538215637, 0.8682889342308044, 0.8635172247886658, 0.8279599547386169, 0.843579113483429, 0.8518442511558533, 0.8710481524467468, 0.8655461072921753, 0.8716715574264526, 0.8486949801445007, 0.8676790595054626, 0.8435341119766235, 0.8438488245010376, 0.8281126022338867, 0.8571349382400513, 0.8572031855583191, 0.8587437868118286, 0.8444743752479553, 0.8233602643013, 0.8346602916717529, 0.845449686050415, 0.8334143161773682, 0.8316606283187866, 0.8626046180725098, 0.8614513874053955, 0.8084557056427002, 0.8593654036521912, 0.8792531490325928, 0.8659343719482422], 'hashcode': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.36.2)'}\n"
     ]
    }
   ],
   "source": [
    "bertscore = load(\"bertscore\")\n",
    "results_bertscore = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "print(results_bertscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84227394-fbd9-44ce-9884-6c0b8cd136a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8183996430039406\n"
     ]
    }
   ],
   "source": [
    "arr = results_bertscore[\"precision\"]\n",
    "print(sum(arr)/len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8431b9a-4631-44e1-95dc-877ff4732f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 19 22:34:48 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.113.01             Driver Version: 535.113.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  | 00000000:81:00.0 Off |                  Off |\n",
      "| 30%   33C    P2              71W / 450W |  14785MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c55f7ba-c8cb-49d9-af1d-ace6ec789529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
